Day 1 â€” Created GitHub account and OSINT repo.

Goal: Document my progress from brickwork to digital analysis.

Today's Accomplishments:
- Organized repository structure with folders: projects/, case-studies/, notebooks/, scripts/, docs/
- Created and published portfolio README page on GitHub
- Set up authentication and connected local repo to GitHub
- Established goals for OSINT investigations and learning path
- Created learning log to track progress

Day 2 â€” Coca-Cola Investigation: UK Traffic Light Labelling System

Goal: Investigate selective health policy and corporate transparency in UK nutritional labelling.

Today's Accomplishments:
- Initiated investigation into Coca-Cola's inconsistent use of traffic light nutritional labelling system in UK
- Documented real-world observation: Coca-Cola can without traffic light colour indicators obtained with meal purchase
- Researched post-Brexit regulatory opportunity for UK to mandate traffic light system
- Investigated government inaction despite public health concerns
- Analysed Coca-Cola's marketing psychology and selective transparency practices
- Compiled comprehensive evidence from multiple sources:
  * House of Lords Report on Food, Diet and Obesity (2024)
  * News articles documenting Coca-Cola's initial rejection and later adoption
  * Industry reports on label-less packaging trials
  * Parliamentary and industry criticism of labelling effectiveness
- Documented lack of transparency in adoption rates (no public data on percentage of products using system)
- Established investigation framework with clear objectives, methodology, research questions, and evidence base
- Converted all documentation to British English (Queen's English) spelling
- Created structured investigation document with sections: Objective, Background, Research Questions, Data Sources, Methodology, Findings, Evidence, Analysis, Conclusion, and Resources
- Pushed all work to GitHub repository with detailed commit messages

Key Findings:
- Traffic light system remains voluntary in UK despite post-Brexit opportunity to mandate it
- Coca-Cola's implementation is inconsistent across products (some have labels, some don't)
- When labels are present, they use "one red, three green" pattern minimising negative visual cues
- 2024 label-less packaging trial removed visible nutritional information entirely
- Industry estimates suggest approximately one-third of all UK food products don't use traffic light system
- No public data available on specific percentage of Coca-Cola products using the system

Day 3 â€” AI Governance Research Essay

Goal: Capture and publish structured thinking on responsible AI development for future reference and public sharing.

Today's Accomplishments:
- Added a dedicated `AI Governance Research` essay to `docs/ai-governance-research.md`, detailing risks, regulatory needs, and strategic priorities.
- Kept the portfolio `README.md` concise by removing the full essay while retaining focus areas and links.
- Published all updates to GitHub with clear commit history for transparency.

Key Takeaways:
- Structuring conceptual research as a standalone document keeps the portfolio entry points clean while preserving depth elsewhere.
- Maintaining British English across documents ensures consistency with previous work.
- Documenting governance concerns now will inform future investigations into AI-related claims and policies.
Learning Log â€” Streamlit Podcast AI App

<<<<<<< HEAD
Today I built and tested a working offline Streamlit application that can take an MP3 file, transcribe it using OpenAI Whisper, and automatically generate timestamps, subtitles, and structured transcript data. The app can now export the transcript in multiple formats, including SRT subtitles, a timestamped text file, raw JSON segments, and a standard .txt version.

I also integrated semantic search using the all-MiniLM-L6-v2 SentenceTransformer model so that the transcript can be searched by meaning, not just keywords. This allows the app to locate ideas, themes, or phrases across the recording, which feels like the first step toward a real personal knowledge search engine.

There were a few technical challenges: missing dependencies, ffmpeg not installed, mismatched virtual environment paths, and a small Git conflict. I resolved each issue, configured the environment correctly, and linked the new project to my existing GitHub repository. The project now saves and pushes cleanly.

The UI also improved today â€” timestamps now display directly inside the app, not only in download files, and the overall layout feels clearer and more user-friendly.

By the end of the session, the project was working, committed, and safely stored in GitHub. Good progress, and a solid foundation for future features.
=======
Day 4 â€” Podcast AI Search Tool Development

Goal: Build a local AI-powered tool for transcribing podcasts and performing semantic search, designed for OSINT workflows and long-form audio analysis.

Today's Accomplishments:
- Created complete podcast transcription and search application using Streamlit, Whisper, and Sentence Transformers
- Built main Streamlit web app (app.py) with:
  * MP3 file upload functionality
  * Local Whisper transcription (base model)
  * Timestamped transcript generation with human-readable format
  * Semantic search using Sentence Transformers (all-MiniLM-L6-v2)
  * Multiple export formats: plain text, timestamped text, JSON segments, SRT subtitles
  * Project saving feature that organises all files into named folders
  * Pre-computed embeddings storage for faster future searches
- Created command-line transcription tool (cli_transcribe.py) with:
  * Batch processing capability
  * Multiple output formats (timestamped TXT, JSON, SRT)
  * Terminal alias setup for quick access
- Implemented timestamped search results showing exact audio positions
- Added project workspace functionality:
  * Save complete projects with all files organised
  * Store embeddings for faster re-searches
  * Metadata tracking (creation date, model versions, segment counts)
- Updated documentation:
  * Comprehensive README.md with installation and usage instructions
  * Requirements.txt with all dependencies
  * .gitignore configured for generated files
- Enhanced UI/UX:
  * Session state management for search
  * Results header showing query
  * Hotkey hints for future keyboard shortcuts
  * Multiple download buttons for different formats
- All processing runs fully offline for privacy and security
- Integrated into osint-portfolio-Malik repository structure

Key Features:
- âš¡ Local Whisper transcription (no cloud)
- ðŸ” Semantic search (meaning-based, not just exact keywords)
- â±ï¸ Timestamped results for precise audio navigation
- ðŸ’¾ Project saving with organised folder structure
- ðŸŽ¬ SRT subtitle generation for video editing
- ðŸ“ Multiple export formats (TXT, JSON, SRT)
- ðŸ§  Pre-computed embeddings for performance
- ðŸ”’ Fully offline processing

Technical Stack:
- Python 3.10+
- Streamlit for web UI
- OpenAI Whisper (base model) for transcription
- Sentence Transformers for semantic search
- FFmpeg for audio processing

Use Cases:
- OSINT investigations requiring audio analysis
- Podcast research and content extraction
- Long-form audio transcription and search
- Creating searchable archives of audio content
- Generating subtitles for video production

Key Takeaways:
- Building local AI tools provides privacy and control over sensitive content
- Semantic search is more powerful than keyword matching for finding concepts
- Timestamped results are essential for navigating long audio files
- Project organisation makes it easy to manage multiple investigations
- Pre-computing embeddings significantly speeds up repeated searches
- Offline processing is crucial for sensitive OSINT work

>>>>>>> 6d466c4 (Add project structure folders for persistence and future expansion)
